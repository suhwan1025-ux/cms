====================================
CMS AI 어시스턴트 서버 실행 가이드
====================================

✅ 패키지 설치 완료!
✅ 환경 변수 설정 완료!

이제 2가지 작업만 하면 됩니다:


1단계: Ollama 설치 및 실행
====================================

1-1. Ollama 다운로드 및 설치:
   https://ollama.com/download
   
   또는 직접 다운로드:
   https://ollama.com/download/OllamaSetup.exe
   
   설치 파일을 다운로드하고 실행하여 설치

1-2. 모델 다운로드:
   PowerShell에서 실행:
   
   ollama pull llama3.1:8b
   
   (약 4.7GB, 5-10분 소요)

1-3. Ollama 서버 실행:
   PowerShell에서 실행:
   
   ollama serve
   
   ⚠️ 이 창은 계속 열어두세요!


2단계: AI 서버 실행
====================================

새 PowerShell 창을 열고:

2-1. ai_server 폴더로 이동:
   cd D:\CMS_NEW\ai_server

2-2. AI 서버 실행:
   C:\Users\USER\AppData\Local\Programs\Python\Python312\python.exe main.py
   
   또는 간단하게:
   python main.py

2-3. 서버가 정상 실행되면:
   🚀 AI 어시스턴트 서버 시작 중...
   ✅ 데이터베이스 연결 확인
   ✅ Ollama 서버 연결 확인
   🎉 AI 어시스턴트 서버 준비 완료!
   
   이런 메시지가 나타납니다!

2-4. 브라우저에서 확인:
   http://localhost:8000
   http://localhost:8000/health


3단계: 프론트엔드에서 테스트
====================================

3-1. CMS 애플리케이션 실행:
   (다른 PowerShell 창에서)
   cd D:\CMS_NEW
   node server.js

3-2. 브라우저에서 접속:
   http://172.22.32.200:3002
   
3-3. 'AI 어시스턴트' 메뉴 클릭
   채팅창에서 질문 입력:
   - "전체 품의서는 몇 건인가요?"
   - "올해 사업예산 총액은 얼마인가요?"
   - "외주인력은 몇 명인가요?"


====================================
문제 해결
====================================

Q: "ollama: command not found" 오류
A: Ollama 설치 후 PowerShell을 재시작하세요.
   또는 전체 경로로 실행:
   C:\Users\USER\AppData\Local\Programs\Ollama\ollama.exe serve

Q: "Ollama 서버 연결 실패" 경고
A: 'ollama serve' 명령이 실행 중인지 확인하세요.
   다른 터미널 창에서 실행되어야 합니다.

Q: "데이터베이스 연결 실패" 경고
A: PostgreSQL이 실행 중인지 확인하세요.
   ai_server/.env 파일의 DB 정보를 확인하세요.

Q: 모델 다운로드가 느려요
A: Ollama는 처음 실행 시 모델을 다운로드합니다 (4.7GB).
   인터넷 속도에 따라 5-10분 소요됩니다.

Q: Python 명령어가 작동하지 않아요
A: 전체 경로를 사용하세요:
   C:\Users\USER\AppData\Local\Programs\Python\Python312\python.exe main.py


====================================
빠른 시작 명령어 요약
====================================

# 터미널 1 - Ollama 서버
ollama serve

# 터미널 2 - AI 서버
cd D:\CMS_NEW\ai_server
python main.py

# 터미널 3 - 백엔드 서버
cd D:\CMS_NEW
node server.js


====================================
다음 단계
====================================

1. Ollama 설치 → https://ollama.com/download
2. ollama pull llama3.1:8b
3. ollama serve (계속 실행)
4. python main.py (ai_server 폴더에서)
5. node server.js (CMS_NEW 폴더에서)
6. 브라우저에서 테스트!


완료! 🎉
====================================

